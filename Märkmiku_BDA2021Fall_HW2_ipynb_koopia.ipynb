{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Märkmiku BDA2021Fall_HW2.ipynb koopia",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd1VgKB3rbXo"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\"><b></b>\n",
        "<h1><center> <font color='black'> Homework 02  </font></center></h1>\n",
        "<h2><center> <font color='black'> Descriptive analysis and visualization</font></center></h2>   \n",
        "<h2><center> <font color='black'> MTAT.03.319 - Business Data Analytics</font></center></h2>\n",
        "<h2><center> <font color='black'> University of Tartu - Fall 2021</font></center></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAnjYOFQnksf"
      },
      "source": [
        "# Homework instructions\n",
        "\n",
        "- Please provide the names and student IDs of the team-members (Maximum 2 person) in the field \"Team mates\" below. If you are not working in a team please insert only your name and student ID. \n",
        "\n",
        "- The accepted submission formats are Colab links or .ipynb files. If you are submitting Colab links please make sure that the privacy settings for the file is public so we can access your code. \n",
        "\n",
        "- The submission will automatically close on <font color='red'>**6 October at 23:59**</font>, so please make sure to submit before the deadline. \n",
        "\n",
        "- ONLY one of the teammates should submit the homework. We will grade the homework and the marks and feedback is applied for both the team members. So please communicate with your team member about marks and feedback if you are submit the homework.\n",
        "\n",
        "- If a question is not clear, please ask us in Moodle ONLY. \n",
        "\n",
        "- For coding related questions, do submit your code as well as your explanation/answer. (Check the homework Description video to know more about it)\n",
        "\n",
        "- After you have finished solving the Homework, please restart the Kernel and run all the cells to check if there is any persisting issues. \n",
        "\n",
        "- Plagiarism is <font color='red'>**PROHIBITED**</font>. Any form of plagiarism will be dealt according to the university policy (https://www.ut.ee/en/current-students/academic-fraud).\n",
        "\n",
        "- Please <font color='red'>do not change</font> the template of this notebook file. You can download the .ipynb file and work on that.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYkuEV8mryiR"
      },
      "source": [
        "**<h2><font color='red'>Team mates:</font></h2>**\n",
        "\n",
        "\n",
        "<font color='red'>Name: Marke Teppor</font>&emsp;   <font color='red'>Student ID:  92858</font>\n",
        "\n",
        "\n",
        "<font color='red'>Name: </font>&emsp;   <font color='red'>Student ID: </font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOdqrTrKnksh"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwSuDsk1nksj"
      },
      "source": [
        "Let's get the Android apps' data! Each app has a name in the **App** column and the rest of the relevant data in the remaining columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NFGr8c2nksl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "12c48829-7693-484a-c002-42a8013e6d13"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"app_data.csv\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e332f096f98a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"app_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'app_data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frLa2-oDdMkC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "ef6f6505-a687-45af-fe9f-05f6830c0904"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ0y3SeTnks1"
      },
      "source": [
        "## Question 1 (2p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdhTymxAnks3"
      },
      "source": [
        "### For each feature in dataset describe it’s meaning, data type (binary, ordinal, etc.) and possible values (ranges for numeric type). The task may seem boring but doing it you will see what issues can be found in real-life data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN3KFVSx7moJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "YX001rq9B1Ik",
        "outputId": "b3e189b8-4787-423f-bbae-2b0fe18c834c"
      },
      "source": [
        "df.info()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a74c58233b9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbnnGNlwnks4"
      },
      "source": [
        "## Question 2 (2p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-XrAXkjnks7"
      },
      "source": [
        "### Clean the dataset, according to the rules below. Write down, which columns and rows were affected and how many rows are left after the cleaning? Please, provide reasoning for your decision. The rest of the homework depends on these results, so be careful with this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2NMy-Grnks8"
      },
      "source": [
        "Rules:\n",
        "\n",
        "    1. App feature must contain unique values.\n",
        "    2. Category feature must contain 15 different values.\n",
        "    3. Rating must be positive and not exceed 5.\n",
        "    4. Amount of reviews must be positive(non-negative)\n",
        "    5. Size must be positive.\n",
        "    6. Amount of installs must be positive.\n",
        "    7. Type of payment should be either “Free” or “Paid”.\n",
        "    8. Price has to be of type float64.\n",
        "    9. NA values should be replced where it's possible.\n",
        "     For example, for numerical values, you can substitude NaN with 0 or impute with mean value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcv5LP5bnks_"
      },
      "source": [
        "_Hint 1: feel free to convert columns to numerical (pd.to_numerical(series)) when it is logical_\n",
        "\n",
        "_Hint 2: don't hesitate to remove/replace string values in order to convert (series.replace({..}, inplace=True, regex=True))_\n",
        "\n",
        "_Hint 3: there is no single correct way to clean the dataset_\n",
        "\n",
        "\n",
        "_Hint 4: for the numerical columns, you need first to remove non-digit strings (like, dollar signs, etc)_\n",
        "\n",
        "\n",
        "_Hint 5: There is a pandas construction pd.Column.apply(lambda x: f(x)) which applies your custom function row by row for all elements in column \"Column\"._\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsZT4MC-uNCm"
      },
      "source": [
        "### For later questions please use the \"cleaned\" dataset obtained after question #2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS8BY5OinktA"
      },
      "source": [
        "## Question 3 (1.5p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyS0X2HjnktB"
      },
      "source": [
        "### Draw a plot of the price to see what type of distribution it has? Think whether it makes sense to include all the apps for price plot building. What is the mean, median, max & min values, standard deviation of the price variable?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyCsMlXrnktC"
      },
      "source": [
        "## Question 4 (1p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYaEc6HfnktE"
      },
      "source": [
        "### Find correlation between the rating and the number of reviews of the applications. \n",
        "### Draw the plot which best suits for showing correlation. What type of correlation does it have (justify your answer)? \n",
        "###Please explain whether the correlation score correctly represents the relation between rating and the number of reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLhk__irnktF"
      },
      "source": [
        "## Question 5 (1p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilIx2XZonktH"
      },
      "source": [
        "### Calculate the average rating for each category. Select the top 5 categories and build a plot that can be used to compare average ratings (justify your choice of a plot type). Interpret the seen results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYd-FB5dnktI"
      },
      "source": [
        "## Question 6 (1.5p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQg4ET0anktL"
      },
      "source": [
        "### Choose 4 categories and for each category build a proper plot that will show how prices vary based on app's rating. Justify your choice of the plot type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCASPaHcnktN"
      },
      "source": [
        "## Question 7 (1p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5-qCU-KnktO"
      },
      "source": [
        "###  1. (0.5p) Create a heatmap to represent relations between the genre and the category. Find the combination (pair of genre and category) with the lowest frequency and with the highest frequency. Was the combination with the biggest frequency clearly seen on the heatmap? \n",
        "### 2. (0.5p) Please write two interesting facts you found from the heatmap?\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64ZXVjmC-BXF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}